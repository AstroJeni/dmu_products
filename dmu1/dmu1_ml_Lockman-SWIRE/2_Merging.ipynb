{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lockman SWIRE master catalogue\n",
    "\n",
    "This notebook presents the merge of the various pristine catalogues to produce HELP mater catalogue on Lockman SWIRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herschelhelp_internal import git_version\n",
    "print(\"This notebook was run with herschelhelp_internal version: \\n{}\".format(git_version()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Column, Table\n",
    "import numpy as np\n",
    "from pymoc import MOC\n",
    "\n",
    "from herschelhelp_internal.masterlist import merge_catalogues, nb_merge_dist_plot, specz_merge\n",
    "from herschelhelp_internal.utils import coords_to_hpidx, ebv, gen_help_id, inMoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMP_DIR = os.environ.get('TMP_DIR', \"./data_tmp\")\n",
    "OUT_DIR = os.environ.get('OUT_DIR', \"./data\")\n",
    "SUFFIX = os.environ.get('SUFFIX', time.strftime(\"_%Y%m%d\"))\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUT_DIR)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Reading the prepared pristine catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wfc = Table.read(\"{}/INT-WFC.fits\".format(TMP_DIR))\n",
    "rcs = Table.read(\"{}/RCSLenS.fits\".format(TMP_DIR))\n",
    "ps1 = Table.read(\"{}/PS1.fits\".format(TMP_DIR))\n",
    "sparcs = Table.read(\"{}/SpARCS.fits\".format(TMP_DIR))\n",
    "dxs = Table.read(\"{}/UKIDSS-DXS.fits\".format(TMP_DIR))\n",
    "swire= Table.read(\"{}/SWIRE.fits\".format(TMP_DIR))\n",
    "servs = Table.read(\"{}/SERVS.fits\".format(TMP_DIR))\n",
    "uhs = Table.read(\"{}/UHS.fits\".format(TMP_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Merging tables\n",
    "\n",
    "We first merge the optical catalogues and then add the infrared ones: WFC, DXS, SpARCS, HSC, PS1, SERVS, SWIRE.\n",
    "\n",
    "At every step, we look at the distribution of the distances to the nearest source in the merged catalogue to determine the best crossmatching radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue = wfc\n",
    "master_catalogue['wfc_ra'].name = 'ra'\n",
    "master_catalogue['wfc_dec'].name = 'dec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add RCSLenS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(rcs['rcs_ra'], rcs['rcs_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, rcs, \"rcs_ra\", \"rcs_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add PanSTARRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(ps1['ps1_ra'], ps1['ps1_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, ps1, \"ps1_ra\", \"ps1_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add SpARCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(sparcs['sparcs_ra'], sparcs['sparcs_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, sparcs, \"sparcs_ra\", \"sparcs_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(dxs['dxs_ra'], dxs['dxs_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 0.8 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, dxs, \"dxs_ra\", \"dxs_dec\", radius=0.8*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add SERVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(servs['servs_ra'], servs['servs_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 1 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, servs, \"servs_ra\", \"servs_dec\", radius=1.*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add SWIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(swire['swire_ra'], swire['swire_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 1 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, swire, \"swire_ra\", \"swire_dec\", radius=1.*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add UHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(uhs['uhs_ra'], uhs['uhs_dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given the graph above, we use 1 arc-second radius\n",
    "master_catalogue = merge_catalogues(master_catalogue, uhs, \"uhs_ra\", \"uhs_dec\", radius=1.*u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "When we merge the catalogues, astropy masks the non-existent values (e.g. when a row comes only from a catalogue and has no counterparts in the other, the columns from the latest are masked for that row). We indicate to use NaN for masked values for floats columns, False for flag columns and -1 for ID columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in master_catalogue.colnames:\n",
    "    if \"m_\" in col or \"merr_\" in col or \"f_\" in col or \"ferr_\" in col or \"stellarity\" in col:\n",
    "        master_catalogue[col].fill_value = np.nan\n",
    "    elif \"flag\" in col:\n",
    "        master_catalogue[col].fill_value = 0\n",
    "    elif \"id\" in col:\n",
    "        master_catalogue[col].fill_value = -1\n",
    "        \n",
    "master_catalogue = master_catalogue.filled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_catalogue[:10].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Merging flags and stellarity\n",
    "\n",
    "Each pristine catalogue contains a flag indicating if the source was associated to a another nearby source that was removed during the cleaning process.  We merge these flags in a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_cleaned_columns = [column for column in master_catalogue.colnames\n",
    "                        if 'flag_cleaned' in column]\n",
    "\n",
    "flag_column = np.zeros(len(master_catalogue), dtype=bool)\n",
    "for column in flag_cleaned_columns:\n",
    "    flag_column |= master_catalogue[column]\n",
    "    \n",
    "master_catalogue.add_column(Column(data=flag_column, name=\"flag_cleaned\"))\n",
    "master_catalogue.remove_columns(flag_cleaned_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pristine catalogue contains a flag indicating the probability of a source being a Gaia object (0: not a Gaia object, 1: possibly, 2: probably, 3: definitely).  We merge these flags taking the highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_gaia_columns = [column for column in master_catalogue.colnames\n",
    "                     if 'flag_gaia' in column]\n",
    "\n",
    "master_catalogue.add_column(Column(\n",
    "    data=np.max([master_catalogue[column] for column in flag_gaia_columns], axis=0),\n",
    "    name=\"flag_gaia\"\n",
    "))\n",
    "master_catalogue.remove_columns(flag_gaia_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each prisitine catalogue may contain one or several stellarity columns indicating the probability (0 to 1) of each source being a star.  We merge these columns taking the highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stellarity_columns = [column for column in master_catalogue.colnames\n",
    "                      if 'stellarity' in column]\n",
    "\n",
    "master_catalogue.add_column(Column(\n",
    "    data=np.nanmax([master_catalogue[column] for column in stellarity_columns], axis=0),\n",
    "    name=\"stellarity\"\n",
    "))\n",
    "master_catalogue.remove_columns(stellarity_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Adding E(B-V) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(\n",
    "    ebv(master_catalogue['ra'], master_catalogue['dec'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V - Adding HELP unique identifiers and field columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(Column(gen_help_id(master_catalogue['ra'], master_catalogue['dec']),\n",
    "                                   name=\"help_id\"))\n",
    "master_catalogue.add_column(Column(np.full(len(master_catalogue), \"Lockman SWIRE\", dtype='<U18'),\n",
    "                                   name=\"field\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the HELP Ids are unique\n",
    "if len(master_catalogue) != len(np.unique(master_catalogue['help_id'])):\n",
    "    print(\"The HELP IDs are not unique!!!\")\n",
    "else:\n",
    "    print(\"OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI - Cross-matching with spec-z catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz =  Table.read(\"../../dmu23/dmu23_Lockman-SWIRE/data/Lockman_SWIRE-specz-v2.1.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_merge_dist_plot(\n",
    "    SkyCoord(master_catalogue['ra'], master_catalogue['dec']),\n",
    "    SkyCoord(specz['ra'] * u.deg, specz['dec'] * u.deg)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue = specz_merge(master_catalogue, specz, radius=1. * u.arcsec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII - Choosing between multiple values for the same filter\n",
    "\n",
    "Both SERVS and SWIRE provide IRAC1 and IRAC2 fluxes. SERVS is deeper but tends to under-estimate flux of bright sources (Mattia said over 2000 µJy) as illustrated by this comparison of SWIRE, SERVS, and Spitzer-EIP fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seip = Table.read(\"../../dmu0/dmu0_SEIP/data/SEIP_Lockman-SWIRE.fits\")\n",
    "seip_coords = SkyCoord(seip['ra'], seip['dec'])\n",
    "idx, d2d, _ = seip_coords.match_to_catalog_sky(SkyCoord(master_catalogue['ra'], master_catalogue['dec']))\n",
    "mask = d2d <= 2 * u.arcsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(seip['i1_f_ap1'][mask], master_catalogue[idx[mask]]['f_ap_servs_irac1'], label=\"SERVS\", s=2.)\n",
    "ax.scatter(seip['i1_f_ap1'][mask], master_catalogue[idx[mask]]['f_ap_swire_irac1'], label=\"SWIRE\", s=2.)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"SEIP flux [μJy]\")\n",
    "ax.set_ylabel(\"SERVS/SWIRE flux [μJy]\")\n",
    "ax.set_title(\"IRAC 1\")\n",
    "ax.legend()\n",
    "ax.axvline(2000, color=\"black\", linestyle=\"--\", linewidth=1.)\n",
    "ax.plot(seip['i1_f_ap1'][mask], seip['i1_f_ap1'][mask], linewidth=.1, color=\"black\", alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(seip['i2_f_ap1'][mask], master_catalogue[idx[mask]]['f_ap_servs_irac2'], label=\"SERVS\", s=2.)\n",
    "ax.scatter(seip['i2_f_ap1'][mask], master_catalogue[idx[mask]]['f_ap_swire_irac2'], label=\"SWIRE\", s=2.)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"SEIP flux [μJy]\")\n",
    "ax.set_ylabel(\"SERVS/SWIRE flux [μJy]\")\n",
    "ax.set_title(\"IRAC 2\")\n",
    "ax.legend()\n",
    "ax.axvline(2000, color=\"black\", linestyle=\"--\", linewidth=1.)\n",
    "\n",
    "ax.plot(seip['i1_f_ap2'][mask], seip['i1_f_ap2'][mask], linewidth=.1, color=\"black\", alpha=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both SWIRE and SERVS fluxes are provided, we use the SERVS flux below 2000 μJy and the SWIRE flux over.\n",
    "\n",
    "We create a table indicating for each source the origin on the IRAC1 and IRAC2 fluxes that will be saved separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irac_origin = Table()\n",
    "irac_origin.add_column(master_catalogue['help_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAC1 aperture flux and magnitudes\n",
    "has_servs = ~np.isnan(master_catalogue['f_ap_servs_irac1'])\n",
    "has_swire = ~np.isnan(master_catalogue['f_ap_swire_irac1'])\n",
    "has_both = has_servs & has_swire\n",
    "\n",
    "print(\"{} sources with SERVS flux\".format(np.sum(has_servs)))\n",
    "print(\"{} sources with SWIRE flux\".format(np.sum(has_swire)))\n",
    "print(\"{} sources with SERVS and SWIRE flux\".format(np.sum(has_both)))\n",
    "\n",
    "has_servs_above_limit = has_servs.copy()\n",
    "has_servs_above_limit[has_servs] = master_catalogue['f_ap_servs_irac1'][has_servs] > 2000\n",
    "\n",
    "use_swire = (has_swire & ~has_servs) | (has_both & has_servs_above_limit)\n",
    "use_servs = (has_servs & ~(has_both & has_servs_above_limit))\n",
    "\n",
    "print(\"{} sources for which we use SERVS\".format(np.sum(use_servs)))\n",
    "print(\"{} sources for which we use SWIRE\".format(np.sum(use_swire)))\n",
    "\n",
    "f_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "f_ap_irac[use_servs] = master_catalogue['f_ap_servs_irac1'][use_servs]\n",
    "f_ap_irac[use_swire] = master_catalogue['f_ap_swire_irac1'][use_swire]\n",
    "\n",
    "ferr_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "ferr_ap_irac[use_servs] = master_catalogue['ferr_ap_servs_irac1'][use_servs]\n",
    "ferr_ap_irac[use_swire] = master_catalogue['ferr_ap_swire_irac1'][use_swire]\n",
    "\n",
    "m_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "m_ap_irac[use_servs] = master_catalogue['m_ap_servs_irac1'][use_servs]\n",
    "m_ap_irac[use_swire] = master_catalogue['m_ap_swire_irac1'][use_swire]\n",
    "\n",
    "merr_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "merr_ap_irac[use_servs] = master_catalogue['merr_ap_servs_irac1'][use_servs]\n",
    "merr_ap_irac[use_swire] = master_catalogue['merr_ap_swire_irac1'][use_swire]\n",
    "\n",
    "master_catalogue.add_column(Column(data=f_ap_irac, name=\"f_ap_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=ferr_ap_irac, name=\"ferr_ap_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=m_ap_irac, name=\"m_ap_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=merr_ap_irac, name=\"merr_ap_irac_i1\"))\n",
    "\n",
    "master_catalogue.remove_columns(['f_ap_servs_irac1', 'f_ap_swire_irac1', 'ferr_ap_servs_irac1',\n",
    "                                     'ferr_ap_swire_irac1', 'm_ap_servs_irac1', 'm_ap_swire_irac1',\n",
    "                                     'merr_ap_servs_irac1', 'merr_ap_swire_irac1'])\n",
    "\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_servs] = \"SERVS\"\n",
    "origin[use_swire] = \"SWIRE\"\n",
    "irac_origin.add_column(Column(data=origin, name=\"IRAC1_app\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAC1 total flux and magnitudes\n",
    "has_servs = ~np.isnan(master_catalogue['f_servs_irac1'])\n",
    "has_swire = ~np.isnan(master_catalogue['f_swire_irac1'])\n",
    "has_both = has_servs & has_swire\n",
    "\n",
    "print(\"{} sources with SERVS flux\".format(np.sum(has_servs)))\n",
    "print(\"{} sources with SWIRE flux\".format(np.sum(has_swire)))\n",
    "print(\"{} sources with SERVS and SWIRE flux\".format(np.sum(has_both)))\n",
    "\n",
    "has_servs_above_limit = has_servs.copy()\n",
    "has_servs_above_limit[has_servs] = master_catalogue['f_servs_irac1'][has_servs] > 2000\n",
    "\n",
    "use_swire = (has_swire & ~has_servs) | (has_both & has_servs_above_limit)\n",
    "use_servs = (has_servs & ~(has_both & has_servs_above_limit))\n",
    "\n",
    "print(\"{} sources for which we use SERVS\".format(np.sum(use_servs)))\n",
    "print(\"{} sources for which we use SWIRE\".format(np.sum(use_swire)))\n",
    "\n",
    "f_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "f_ap_irac[use_servs] = master_catalogue['f_servs_irac1'][use_servs]\n",
    "f_ap_irac[use_swire] = master_catalogue['f_swire_irac1'][use_swire]\n",
    "\n",
    "ferr_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "ferr_ap_irac[use_servs] = master_catalogue['ferr_servs_irac1'][use_servs]\n",
    "ferr_ap_irac[use_swire] = master_catalogue['ferr_swire_irac1'][use_swire]\n",
    "\n",
    "flag_irac = np.full(len(master_catalogue), False, dtype=bool)\n",
    "flag_irac[use_servs] = master_catalogue['flag_servs_irac1'][use_servs]\n",
    "flag_irac[use_swire] = master_catalogue['flag_swire_irac1'][use_swire]\n",
    "\n",
    "m_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "m_ap_irac[use_servs] = master_catalogue['m_servs_irac1'][use_servs]\n",
    "m_ap_irac[use_swire] = master_catalogue['m_swire_irac1'][use_swire]\n",
    "\n",
    "merr_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "merr_ap_irac[use_servs] = master_catalogue['merr_servs_irac1'][use_servs]\n",
    "merr_ap_irac[use_swire] = master_catalogue['merr_swire_irac1'][use_swire]\n",
    "\n",
    "master_catalogue.add_column(Column(data=f_ap_irac, name=\"f_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=ferr_ap_irac, name=\"ferr_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=m_ap_irac, name=\"m_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=merr_ap_irac, name=\"merr_irac_i1\"))\n",
    "master_catalogue.add_column(Column(data=flag_irac, name=\"flag_irac_i1\"))\n",
    "\n",
    "master_catalogue.remove_columns(['f_servs_irac1', 'f_swire_irac1', 'ferr_servs_irac1',\n",
    "                                 'ferr_swire_irac1', 'm_servs_irac1', 'flag_servs_irac1', 'm_swire_irac1',\n",
    "                                 'merr_servs_irac1', 'merr_swire_irac1', 'flag_swire_irac1'])\n",
    "\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_servs] = \"SERVS\"\n",
    "origin[use_swire] = \"SWIRE\"\n",
    "irac_origin.add_column(Column(data=origin, name=\"IRAC1_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAC2 aperture flux and magnitudes\n",
    "has_servs = ~np.isnan(master_catalogue['f_ap_servs_irac2'])\n",
    "has_swire = ~np.isnan(master_catalogue['f_ap_swire_irac2'])\n",
    "has_both = has_servs & has_swire\n",
    "\n",
    "print(\"{} sources with SERVS flux\".format(np.sum(has_servs)))\n",
    "print(\"{} sources with SWIRE flux\".format(np.sum(has_swire)))\n",
    "print(\"{} sources with SERVS and SWIRE flux\".format(np.sum(has_both)))\n",
    "\n",
    "has_servs_above_limit = has_servs.copy()\n",
    "has_servs_above_limit[has_servs] = master_catalogue['f_ap_servs_irac2'][has_servs] > 2000\n",
    "\n",
    "use_swire = (has_swire & ~has_servs) | (has_both & has_servs_above_limit)\n",
    "use_servs = (has_servs & ~(has_both & has_servs_above_limit))\n",
    "\n",
    "print(\"{} sources for which we use SERVS\".format(np.sum(use_servs)))\n",
    "print(\"{} sources for which we use SWIRE\".format(np.sum(use_swire)))\n",
    "\n",
    "f_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "f_ap_irac[use_servs] = master_catalogue['f_ap_servs_irac2'][use_servs]\n",
    "f_ap_irac[use_swire] = master_catalogue['f_ap_swire_irac2'][use_swire]\n",
    "\n",
    "ferr_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "ferr_ap_irac[use_servs] = master_catalogue['ferr_ap_servs_irac2'][use_servs]\n",
    "ferr_ap_irac[use_swire] = master_catalogue['ferr_ap_swire_irac2'][use_swire]\n",
    "\n",
    "m_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "m_ap_irac[use_servs] = master_catalogue['m_ap_servs_irac2'][use_servs]\n",
    "m_ap_irac[use_swire] = master_catalogue['m_ap_swire_irac2'][use_swire]\n",
    "\n",
    "merr_ap_irac = np.full(len(master_catalogue), np.nan)\n",
    "merr_ap_irac[use_servs] = master_catalogue['merr_ap_servs_irac2'][use_servs]\n",
    "merr_ap_irac[use_swire] = master_catalogue['merr_ap_swire_irac2'][use_swire]\n",
    "\n",
    "master_catalogue.add_column(Column(data=f_ap_irac, name=\"f_ap_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=ferr_ap_irac, name=\"ferr_ap_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=m_ap_irac, name=\"m_ap_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=merr_ap_irac, name=\"merr_ap_irac_i2\"))\n",
    "\n",
    "master_catalogue.remove_columns(['f_ap_servs_irac2', 'f_ap_swire_irac2', 'ferr_ap_servs_irac2',\n",
    "                                 'ferr_ap_swire_irac2', 'm_ap_servs_irac2', 'm_ap_swire_irac2',\n",
    "                                 'merr_ap_servs_irac2', 'merr_ap_swire_irac2'])\n",
    "\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_servs] = \"SERVS\"\n",
    "origin[use_swire] = \"SWIRE\"\n",
    "irac_origin.add_column(Column(data=origin, name=\"IRAC2_app\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAC2 total flux and magnitudes\n",
    "has_servs = ~np.isnan(master_catalogue['f_servs_irac2'])\n",
    "has_swire = ~np.isnan(master_catalogue['f_swire_irac2'])\n",
    "has_both = has_servs & has_swire\n",
    "\n",
    "print(\"{} sources with SERVS flux\".format(np.sum(has_servs)))\n",
    "print(\"{} sources with SWIRE flux\".format(np.sum(has_swire)))\n",
    "print(\"{} sources with SERVS and SWIRE flux\".format(np.sum(has_both)))\n",
    "\n",
    "has_servs_above_limit = has_servs.copy()\n",
    "has_servs_above_limit[has_servs] = master_catalogue['f_servs_irac2'][has_servs] > 2000\n",
    "\n",
    "use_swire = (has_swire & ~has_servs) | (has_both & has_servs_above_limit)\n",
    "use_servs = (has_servs & ~(has_both & has_servs_above_limit))\n",
    "\n",
    "print(\"{} sources for which we use SERVS\".format(np.sum(use_servs)))\n",
    "print(\"{} sources for which we use SWIRE\".format(np.sum(use_swire)))\n",
    "\n",
    "f_irac = np.full(len(master_catalogue), np.nan)\n",
    "f_irac[use_servs] = master_catalogue['f_servs_irac2'][use_servs]\n",
    "f_irac[use_swire] = master_catalogue['f_swire_irac2'][use_swire]\n",
    "\n",
    "ferr_irac = np.full(len(master_catalogue), np.nan)\n",
    "ferr_irac[use_servs] = master_catalogue['ferr_servs_irac2'][use_servs]\n",
    "ferr_irac[use_swire] = master_catalogue['ferr_swire_irac2'][use_swire]\n",
    "\n",
    "flag_irac = np.full(len(master_catalogue), False, dtype=bool)\n",
    "flag_irac[use_servs] = master_catalogue['flag_servs_irac2'][use_servs]\n",
    "flag_irac[use_swire] = master_catalogue['flag_swire_irac2'][use_swire]\n",
    "\n",
    "m_irac = np.full(len(master_catalogue), np.nan)\n",
    "m_irac[use_servs] = master_catalogue['m_servs_irac2'][use_servs]\n",
    "m_irac[use_swire] = master_catalogue['m_swire_irac2'][use_swire]\n",
    "\n",
    "merr_irac = np.full(len(master_catalogue), np.nan)\n",
    "merr_irac[use_servs] = master_catalogue['merr_servs_irac2'][use_servs]\n",
    "merr_irac[use_swire] = master_catalogue['merr_swire_irac2'][use_swire]\n",
    "\n",
    "master_catalogue.add_column(Column(data=f_irac, name=\"f_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=ferr_irac, name=\"ferr_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=m_irac, name=\"m_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=merr_irac, name=\"merr_irac_i2\"))\n",
    "master_catalogue.add_column(Column(data=flag_irac, name=\"flag_irac_i2\"))\n",
    "\n",
    "master_catalogue.remove_columns(['f_servs_irac2', 'f_swire_irac2', 'ferr_servs_irac2',\n",
    "                                 'ferr_swire_irac2', 'm_servs_irac2', 'flag_servs_irac2', 'm_swire_irac2',\n",
    "                                 'merr_servs_irac2', 'merr_swire_irac2', 'flag_swire_irac2'])\n",
    "\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_servs] = \"SERVS\"\n",
    "origin[use_swire] = \"SWIRE\"\n",
    "irac_origin.add_column(Column(data=origin, name=\"IRAC2_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irac_origin.write(\"{}/lockman-swire_irac_fluxes_origins{}.fits\".format(OUT_DIR, SUFFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UHS WFCAM J vs DXS WFCAM J\n",
    "\n",
    "These both come from wfcam. If UHS is to be included (it currently is not) we will have to decide between the two. DXS is deeper so it would probably be a case of preferentially taking DXS J fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfcam_origin = Table()\n",
    "wfcam_origin.add_column(master_catalogue['help_id'])\n",
    "\n",
    "#Total J flux\n",
    "use_dxs = ~np.isnan(master_catalogue['f_ukidss_j'])\n",
    "use_uhs = np.isnan(master_catalogue['f_ukidss_j']) & ~np.isnan(master_catalogue['f_uhs_j'])\n",
    "\n",
    "f_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "f_wfcam[use_uhs] = master_catalogue['f_uhs_j'][use_uhs]\n",
    "f_wfcam[use_dxs] = master_catalogue['f_ukidss_j'][use_dxs]\n",
    "\n",
    "ferr_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "ferr_wfcam[use_uhs] = master_catalogue['ferr_uhs_j'][use_uhs]\n",
    "ferr_wfcam[use_dxs] = master_catalogue['ferr_ukidss_j'][use_dxs]\n",
    "\n",
    "m_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "m_wfcam[use_uhs] = master_catalogue['m_uhs_j'][use_uhs]\n",
    "m_wfcam[use_dxs] = master_catalogue['m_ukidss_j'][use_dxs]\n",
    "\n",
    "merr_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "merr_wfcam[use_uhs] = master_catalogue['merr_uhs_j'][use_uhs]\n",
    "merr_wfcam[use_dxs] = master_catalogue['merr_ukidss_j'][use_dxs]\n",
    "\n",
    "flag_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "flag_wfcam[use_uhs] = master_catalogue['flag_uhs_j'][use_uhs]\n",
    "flag_wfcam[use_dxs] = master_catalogue['flag_ukidss_j'][use_dxs]\n",
    "\n",
    "#master_catalogue.add_column(Column(data=f_wfcam, name=\"f_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=ferr_wfcam, name=\"ferr_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=m_wfcam, name=\"m_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=merr_wfcam, name=\"merr_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=flag_wfcam, name=\"flag_wfcam_j\"))\n",
    "\n",
    "master_catalogue.remove_columns(['f_uhs_j', 'f_ukidss_j', \n",
    "                                 'ferr_uhs_j', 'ferr_ukidss_j', \n",
    "                                 'm_uhs_j', 'm_ukidss_j',\n",
    "                                 'merr_uhs_j', 'merr_ukidss_j', \n",
    "                                 'flag_uhs_j',  'flag_ukidss_j'])\n",
    "\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_uhs] = \"UHS\"\n",
    "origin[use_dxs] = \"DXS\"\n",
    "wfcam_origin.add_column(Column(data=origin, name=\"wfcam_j\"))\n",
    "\n",
    "#Aperture J flux\n",
    "use_ap_dxs = ~np.isnan(master_catalogue['f_ap_ukidss_j'])\n",
    "use_ap_uhs = np.isnan(master_catalogue['f_ap_ukidss_j']) & ~np.isnan(master_catalogue['f_ap_uhs_j'])\n",
    "\n",
    "f_ap_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "f_ap_wfcam[use_ap_uhs] = master_catalogue['f_ap_uhs_j'][use_ap_uhs]\n",
    "f_ap_wfcam[use_ap_dxs] = master_catalogue['f_ap_ukidss_j'][use_ap_dxs]\n",
    "\n",
    "ferr_ap_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "ferr_ap_wfcam[use_ap_uhs] = master_catalogue['ferr_ap_uhs_j'][use_ap_uhs]\n",
    "ferr_ap_wfcam[use_ap_dxs] = master_catalogue['ferr_ap_ukidss_j'][use_ap_dxs]\n",
    "\n",
    "m_ap_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "m_ap_wfcam[use_ap_uhs] = master_catalogue['m_ap_uhs_j'][use_ap_uhs]\n",
    "m_ap_wfcam[use_ap_dxs] = master_catalogue['m_ap_ukidss_j'][use_ap_dxs]\n",
    "\n",
    "merr_ap_wfcam = np.full(len(master_catalogue), np.nan)\n",
    "merr_ap_wfcam[use_ap_uhs] = master_catalogue['merr_ap_uhs_j'][use_ap_uhs]\n",
    "merr_ap_wfcam[use_ap_dxs] = master_catalogue['merr_ap_ukidss_j'][use_ap_dxs]\n",
    "\n",
    "\n",
    "master_catalogue.add_column(Column(data=f_ap_wfcam, name=\"f_ap_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=ferr_ap_wfcam, name=\"ferr_ap_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=m_ap_wfcam, name=\"m_ap_wfcam_j\"))\n",
    "master_catalogue.add_column(Column(data=merr_ap_wfcam, name=\"merr_ap_wfcam_j\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.remove_columns(['f_ap_uhs_j', 'f_ap_ukidss_j', \n",
    "                                 'ferr_ap_uhs_j', 'ferr_ap_ukidss_j', \n",
    "                                 'm_ap_uhs_j', 'm_ap_ukidss_j',\n",
    "                                 'merr_ap_uhs_j', 'merr_ap_ukidss_j'])\n",
    "\n",
    "origin = np.full(len(master_catalogue), '     ', dtype='<U5')\n",
    "origin[use_ap_uhs] = \"UHS\"\n",
    "origin[use_ap_dxs] = \"DXS\"\n",
    "wfcam_origin.add_column(Column(data=origin, name=\"wfcam_ap_j\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wfcam_origin.write(\"{}/lockman-swire_wfcam_fluxes_origins{}.fits\".format(OUT_DIR, SUFFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue['m_ukidss_k'].name = 'm_wfcam_k'\n",
    "master_catalogue['merr_ukidss_k'].name = 'merr_wfcam_k'\n",
    "master_catalogue['f_ukidss_k'].name = 'f_wfcam_k'\n",
    "master_catalogue['ferr_ukidss_k'].name = 'ferr_wfcam_k'\n",
    "master_catalogue['flag_ukidss_k'].name = 'flag_wfcam_k'\n",
    "master_catalogue['m_ap_ukidss_k'].name = 'm_ap_wfcam_k'\n",
    "master_catalogue['merr_ap_ukidss_k'].name = 'merr_ap_wfcam_k'\n",
    "master_catalogue['f_ap_ukidss_k'].name = 'f_ap_wfcam_k'\n",
    "master_catalogue['ferr_ap_ukidss_k'].name = 'ferr_ap_wfcam_k'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII.a Wavelenght domain coverage\n",
    "\n",
    "We add a binary `flag_optnir_obs` indicating that a source was observed in a given wavelenght domain:\n",
    "\n",
    "- 1 for observation in optical;\n",
    "- 2 for observation in near-infrared;\n",
    "- 4 for observation in mid-infrared (IRAC).\n",
    "\n",
    "It's an integer binary flag, so a source observed both in optical and near-infrared by not in mid-infrared would have this flag at 1 + 2 = 3.\n",
    "\n",
    "*Note 1: The observation flag is based on the creation of multi-order coverage maps from the catalogues, this may not be accurate, especially on the edges of the coverage.*\n",
    "\n",
    "*Note 2: Being on the observation coverage does not mean having fluxes in that wavelength domain. For sources observed in one domain but having no flux in it, one must take into consideration de different depths in the catalogue we are using.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfc_moc = MOC(filename=\"../../dmu0/dmu0_INTWFC/data/lh_intwfc_v2.1_HELP_coverage_MOC.fits\")\n",
    "sparcs_moc = MOC(filename=\"../../dmu0/dmu0_SpARCS/data/SpARCS_HELP_Lockman-SWIRE_MOC.fits\")\n",
    "rcs_moc = MOC(filename=\"../../dmu0/dmu0_RCSLenS/data/RCSLenS_Lockman-SWIRE_MOC.fits\")\n",
    "ps1_moc = MOC(filename=\"../../dmu0/dmu0_PanSTARRS1-3SS/data/PanSTARRS1-3SS_Lockman-SWIRE_MOC.fits\")\n",
    "dxs_moc = MOC(filename=\"../../dmu0/dmu0_UKIDSS-DXS_DR10plus/data/UKIDSS-DR10plus_Lockman-SWIRE_MOC.fits\")\n",
    "servs_moc = MOC(filename=\"../../dmu0/dmu0_DataFusion-Spitzer/data/DF-SERVS_Lockman-SWIRE_MOC.fits\")\n",
    "swire_moc = MOC(filename=\"../../dmu0/dmu0_DataFusion-Spitzer/data/DF-SWIRE_Lockman-SWIRE_MOC.fits\")\n",
    "uhs_moc = MOC(filename=\"../../dmu0/dmu0_UHS/data/UHS-DR1_Lockman-SWIRE_MOC.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "was_observed_optical = inMoc(\n",
    "    master_catalogue['ra'], master_catalogue['dec'],\n",
    "    wfc_moc + sparcs_moc + rcs_moc + ps1_moc) \n",
    "\n",
    "was_observed_nir = inMoc(\n",
    "    master_catalogue['ra'], master_catalogue['dec'],\n",
    "    dxs_moc  + uhs_moc\n",
    ")\n",
    "\n",
    "was_observed_mir = inMoc(\n",
    "    master_catalogue['ra'], master_catalogue['dec'],\n",
    "    servs_moc + swire_moc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(\n",
    "    Column(\n",
    "        1 * was_observed_optical + 2 * was_observed_nir + 4 * was_observed_mir,\n",
    "        name=\"flag_optnir_obs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII.b Wavelenght domain detection\n",
    "\n",
    "We add a binary `flag_optnir_det` indicating that a source was detected in a given wavelenght domain:\n",
    "\n",
    "- 1 for detection in optical;\n",
    "- 2 for detection in near-infrared;\n",
    "- 4 for detection in mid-infrared (IRAC).\n",
    "\n",
    "It's an integer binary flag, so a source detected both in optical and near-infrared by not in mid-infrared would have this flag at 1 + 2 = 3.\n",
    "\n",
    "*Note 1: We use the total flux columns to know if the source has flux, in some catalogues, we may have aperture flux and no total flux.*\n",
    "\n",
    "To get rid of artefacts (chip edges, star flares, etc.) we consider that a source is detected in one wavelength domain when it has a flux value in **at least two bands**. That means that good sources will be excluded from this flag when they are on the coverage of only one band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpARCS is a catalogue of sources detected in r (with fluxes measured at \n",
    "# this prior position in the other bands).  Thus, we are only using the r\n",
    "# CFHT band.\n",
    "# Check to use catalogue flags from HSC and PanSTARRS.\n",
    "nb_optical_flux = (\n",
    "    1 * ~np.isnan(master_catalogue['f_wfc_u']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_wfc_g']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_wfc_r']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_wfc_i']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_wfc_z']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_gpc1_g']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_gpc1_r']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_gpc1_i']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_gpc1_z']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_gpc1_y'])\n",
    ")\n",
    "\n",
    "nb_nir_flux = (\n",
    "    1 * ~np.isnan(master_catalogue['f_wfcam_j']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_wfcam_k'])\n",
    ")\n",
    "\n",
    "nb_mir_flux = (\n",
    "    1 * ~np.isnan(master_catalogue['f_irac_i1']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_irac_i2']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_irac_i3']) +\n",
    "    1 * ~np.isnan(master_catalogue['f_irac_i4'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_optical_flux = nb_optical_flux >= 2\n",
    "has_nir_flux = nb_nir_flux >= 2\n",
    "has_mir_flux = nb_mir_flux >= 2\n",
    "\n",
    "master_catalogue.add_column(\n",
    "    Column(\n",
    "        1 * has_optical_flux + 2 * has_nir_flux + 4 * has_mir_flux,\n",
    "        name=\"flag_optnir_det\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX - Cross-identification table\n",
    "\n",
    "We are producing a table associating to each HELP identifier, the identifiers of the sources in the pristine catalogue. This can be used to easily get additional information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_names = []\n",
    "for col in master_catalogue.colnames:\n",
    "    if '_id' in col:\n",
    "        id_names += [col]\n",
    "    if '_intid' in col:\n",
    "        id_names += [col]\n",
    "        \n",
    "print(id_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue[id_names].write(\n",
    "    \"{}/master_list_cross_ident_lockman-swire{}.fits\".format(OUT_DIR, SUFFIX))\n",
    "id_names.remove('help_id')\n",
    "master_catalogue.remove_columns(id_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X - Adding HEALPix index\n",
    "\n",
    "We are adding a column with a HEALPix index at order 13 associated with each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_catalogue.add_column(Column(\n",
    "    data=coords_to_hpidx(master_catalogue['ra'], master_catalogue['dec'], order=13),\n",
    "    name=\"hp_idx\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XI - Saving the catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"help_id\", \"field\", \"ra\", \"dec\", \"hp_idx\"]\n",
    "\n",
    "bands = [column[5:] for column in master_catalogue.colnames if 'f_ap' in column]\n",
    "for band in bands:\n",
    "    columns += [\"f_ap_{}\".format(band), \"ferr_ap_{}\".format(band),\n",
    "                \"m_ap_{}\".format(band), \"merr_ap_{}\".format(band),\n",
    "                \"f_{}\".format(band), \"ferr_{}\".format(band),\n",
    "                \"m_{}\".format(band), \"merr_{}\".format(band),\n",
    "                \"flag_{}\".format(band)]    \n",
    "    \n",
    "columns += [\"stellarity\", \"flag_cleaned\", \"flag_merged\", \"flag_gaia\", \"flag_optnir_obs\", \"flag_optnir_det\", \n",
    "            \"zspec\", \"zspec_qual\", \"zspec_association_flag\", \"ebv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check for columns in the master catalogue that we will not save to disk.\n",
    "print(\"Missing columns: {}\".format(set(master_catalogue.colnames) - set(columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_catalogue[columns].write(\"{}/master_catalogue_lockman-swire{}.fits\".format(OUT_DIR, SUFFIX))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (herschelhelp_internal)",
   "language": "python",
   "name": "helpint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
